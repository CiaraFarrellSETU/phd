{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVwXeMA65LnmTjB+BE7U1m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CiaraFarrellSETU/phd/blob/main/kmean_rf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H1jmtw_Nm5Pd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from google.colab import widgets\n",
        "import os\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import rasterio\n",
        "from shapely.geometry import Point\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from rasterio.windows import Window\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import KFold, cross_val_predict\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import warnings\n",
        "from rasterio.warp import calculate_default_transform, reproject\n",
        "from rasterio.enums import Resampling\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from skimage import morphology\n",
        "import joblib\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.enums import Resampling\n",
        "from rasterio.warp import calculate_default_transform, reproject\n",
        "from rasterio.mask import mask\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0rzd-nzm83-",
        "outputId": "3f2b8e24-56f4-4f76-cf0b-77ba0b9d79e6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "zip_path = input(\"Please paste the path to your zip file from the sidebar: \")\n",
        "destination = \"/content/dataset\"\n",
        "\n",
        "if os.path.exists(zip_path):\n",
        "    !unzip -q \"{zip_path}\" -d \"{destination}\"\n",
        "    print(f\"Successfully unzipped to {destination}\")\n",
        "else:\n",
        "    print(\"Error: File path not found. Did you mount your drive?\")\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfo7FCe9nBW2",
        "outputId": "5862cda1-6f87-468f-e8f6-933ff13a627e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please paste the path to your zip file from the sidebar: /content/drive/MyDrive/scraghbog.zip\n",
            "Successfully unzipped to /content/dataset\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "S_RGB_PATH = input(\"Summer RGB Path: \")\n",
        "S_NDVI_PATH = input(\"Summer NDVI Path: \")\n",
        "S_DSM = input(\"Summer DSM Path: \")\n",
        "W_RGB_PATH = input(\"Winter RGB Path: \")\n",
        "W_NDVI_PATH = input(\"Winter NDVI Path: \")\n",
        "W_DSM = input(\"Winter DSM Path: \")\n",
        "SHP_PATH = input(\"Shapefile (.shp) Path: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTo2SwtSnNb9",
        "outputId": "f702ac1d-99d8-49ca-8cd1-05d3b91ff80e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summer RGB Path: /content/dataset/scraghbog/scraghbog_rgb_summer.tif\n",
            "Summer NDVI Path: /content/dataset/scraghbog/Scraghbog_Summer_NDVI.tif\n",
            "Summer DSM Path: /content/dataset/scraghbog/scraghbog_dem_summer.tif\n",
            "Winter RGB Path: /content/dataset/scraghbog/Scraghbog_RGB_winter.tif\n",
            "Winter NDVI Path: /content/dataset/scraghbog/Scraghbog_Winter_NDVI.tif\n",
            "Winter DSM Path: /content/dataset/scraghbog/Scraghbog_Winter_DSM.tif\n",
            "Shapefile (.shp) Path: /content/dataset/scraghbog/scraghBog_habiMap.shp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL_COL = 'fid'\n",
        "NAME_COL = 'HCH_MAPPED'\n",
        "\n",
        "gdf = gpd.read_file(SHP_PATH)\n",
        "\n",
        "\n",
        "KERNEL = 17\n",
        "TARGET_RES = 0.5 # Meters\n",
        "EPS = 1e-7\n"
      ],
      "metadata": {
        "id": "1mabbT7EnQaF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resample_raster(path, target_res, master_params=None):\n",
        "    with rasterio.open(path) as src:\n",
        "        if master_params is None:\n",
        "            transform, width, height = calculate_default_transform(\n",
        "                src.crs, src.crs, src.width, src.height, *src.bounds, resolution=target_res)\n",
        "            dst_crs = src.crs\n",
        "        else:\n",
        "            transform = master_params['transform']\n",
        "            width = master_params['width']\n",
        "            height = master_params['height']\n",
        "            dst_crs = master_params['crs']\n",
        "\n",
        "        data = np.zeros((src.count, height, width), dtype='float32')\n",
        "        reproject(\n",
        "            source=rasterio.band(src, list(range(1, src.count + 1))),\n",
        "            destination=data,\n",
        "            src_transform=src.transform,\n",
        "            src_crs=src.crs,\n",
        "            dst_transform=transform,\n",
        "            dst_crs=dst_crs,\n",
        "            resampling=Resampling.bilinear\n",
        "        )\n",
        "        return data, {'transform': transform, 'width': width, 'height': height, 'crs': dst_crs}"
      ],
      "metadata": {
        "id": "nxSDR5CgOXCz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n[1/4] Resampling and Aligning all layers to 0.5m...\")\n",
        "s_rgb_data, m_params = resample_raster(S_RGB_PATH, TARGET_RES)\n",
        "s_nd_data, _  = resample_raster(S_NDVI_PATH, TARGET_RES, m_params)\n",
        "s_dsm_data, _ = resample_raster(S_DSM,       TARGET_RES, m_params)\n",
        "w_rgb_data, _ = resample_raster(W_RGB_PATH, TARGET_RES, m_params)\n",
        "w_nd_data, _  = resample_raster(W_NDVI_PATH, TARGET_RES, m_params)\n",
        "w_dsm_data, _ = resample_raster(W_DSM,       TARGET_RES, m_params)\n",
        "\n",
        "layers = {'s_rgb': s_rgb_data, 's_ndvi': s_nd_data, 's_dsm': s_dsm_data,\n",
        "          'w_rgb': w_rgb_data, 'w_ndvi': w_nd_data, 'w_dsm': w_dsm_data}\n",
        "\n",
        "print(\"[2/4] Extracting every pixel inside polygons...\")\n",
        "gdf = gpd.read_file(SHP_PATH).to_crs(m_params['crs'])\n",
        "\n",
        "fossitt_merger = {\n",
        "    'GS4': 'Grassland', 'PF1' : 'fen & flush', 'PF3': 'bog',\n",
        "    'WD4': 'Tree plantation', 'WN6': 'willow', 'WN7': 'bog woodland',\n",
        "    'FS1': 'Swamp reeds', 'FS2': 'Swamp', 'FW2/WL2': 'water'\n",
        "}\n",
        "gdf['merged_name'] = gdf[NAME_COL].replace(fossitt_merger)\n",
        "le = LabelEncoder()\n",
        "gdf['class_encoded'] = le.fit_transform(gdf['merged_name'])\n",
        "\n",
        "X_list, y_list = [], []\n",
        "\n",
        "for _, row in gdf.iterrows():\n",
        "    try:\n",
        "        poly_pixels = {}\n",
        "        for k, data in layers.items():\n",
        "            # MemoryFile used for fast masking in RAM\n",
        "            with rasterio.io.MemoryFile() as memfile:\n",
        "                with memfile.open(driver='GTiff', height=m_params['height'], width=m_params['width'],\n",
        "                                  count=data.shape[0], crs=m_params['crs'],\n",
        "                                  transform=m_params['transform'], dtype='float32') as mem:\n",
        "                    mem.write(data)\n",
        "                    out_img, _ = mask(mem, [row['geometry']], crop=True)\n",
        "                    poly_pixels[k] = out_img\n",
        "\n",
        "        # Mask 2D: identifying valid pixels (not NoData)\n",
        "        mask_2d = ~np.isnan(poly_pixels['s_ndvi'][0])\n",
        "        idx = np.where(mask_2d)\n",
        "\n",
        "        if len(idx[0]) > 0:\n",
        "            # Extract raw values for every pixel\n",
        "            s_r, s_g, s_b = poly_pixels['s_rgb'][:, idx[0], idx[1]]\n",
        "            w_r, w_g, w_b = poly_pixels['w_rgb'][:, idx[0], idx[1]]\n",
        "            s_nd = poly_pixels['s_ndvi'][0, idx[0], idx[1]]\n",
        "            w_nd = poly_pixels['w_ndvi'][0, idx[0], idx[1]]\n",
        "            s_h = poly_pixels['s_dsm'][0, idx[0], idx[1]]\n",
        "            w_h = poly_pixels['w_dsm'][0, idx[0], idx[1]]\n",
        "\n",
        "            # Feature Calculation (Pixel-wise)\n",
        "            s_vari = (s_g - s_r) / (s_g + s_r - s_b + EPS)\n",
        "            w_vari = (w_g - w_r) / (w_g + w_r - w_b + EPS)\n",
        "\n",
        "            # Stack 12 basic features\n",
        "            pixel_features = np.column_stack([\n",
        "                s_r, s_g, s_b, w_r, w_g, w_b,\n",
        "                s_nd, w_nd, s_nd - w_nd, # Delta NDVI\n",
        "                s_vari, w_vari,\n",
        "                s_h, w_h, s_h - w_h     # Delta Height\n",
        "            ])\n",
        "\n",
        "            X_list.append(pixel_features)\n",
        "            y_list.append(np.full(len(pixel_features), row['class_encoded']))\n",
        "    except: continue\n",
        "\n",
        "X = np.nan_to_num(np.vstack(X_list))\n",
        "y = np.concatenate(y_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWz6jL8gQeln",
        "outputId": "b4a94d46-e25d-4283-ddac-746e7918a8ca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[1/4] Resampling and Aligning all layers to 0.5m...\n",
            "[2/4] Extracting every pixel inside polygons...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PIXEL COUNT DIAGNOSTICS ---\n",
        "print(\"\\n\" + \"-\"*30)\n",
        "print(\"PIXELS EXTRACTED PER CLASS\")\n",
        "print(\"-\"*30)\n",
        "\n",
        "# Count the occurrences of each encoded class in y\n",
        "unique, counts = np.unique(y, return_counts=True)\n",
        "\n",
        "# Create a summary table\n",
        "pixel_counts = pd.DataFrame({\n",
        "    'Class Name': [le.classes_[i] for i in unique],\n",
        "    'Pixel Count': counts\n",
        "}).sort_values(by='Pixel Count', ascending=False)\n",
        "\n",
        "print(pixel_counts.to_string(index=False))\n",
        "print(f\"\\nTotal Pixels for Training: {X.shape[0]}\")\n",
        "print(\"-\"*30 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QKppY9HQv-G",
        "outputId": "7c166595-e051-4e5f-d507-d2b7a48c3023"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------------------------\n",
            "PIXELS EXTRACTED PER CLASS\n",
            "------------------------------\n",
            "     Class Name  Pixel Count\n",
            "            bog      1144900\n",
            "          Swamp       711713\n",
            "         willow       388440\n",
            "   bog woodland       376113\n",
            "Tree plantation       229830\n",
            "      Grassland       209341\n",
            "    fen & flush       152208\n",
            "          water        70210\n",
            "    Swamp reeds        15882\n",
            "\n",
            "Total Pixels for Training: 3298637\n",
            "------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. SUB-SAMPLING ---\n",
        "MAX_PIXELS_PER_CLASS = 100000\n",
        "X_balanced, y_balanced = [], []\n",
        "\n",
        "print(f\"Sub-sampling classes to a max of {MAX_PIXELS_PER_CLASS}...\")\n",
        "for class_idx in np.unique(y):\n",
        "    indices = np.where(y == class_idx)[0]\n",
        "    if len(indices) > MAX_PIXELS_PER_CLASS:\n",
        "        indices = np.random.choice(indices, MAX_PIXELS_PER_CLASS, replace=False)\n",
        "    X_balanced.append(X[indices])\n",
        "    y_balanced.append(y[indices])\n",
        "\n",
        "X = np.vstack(X_balanced)\n",
        "y = np.concatenate(y_balanced)\n",
        "\n",
        "# --- 2. CRITICAL CLEANING ---\n",
        "# Replace Inf with large numbers and NaN with 0\n",
        "X = np.nan_to_num(X, nan=0.0, posinf=1e6, neginf=-1e6)\n",
        "\n",
        "# Clip to ensure no extreme outliers break the Scaler\n",
        "X = np.clip(X, -1e6, 1e6)\n",
        "\n",
        "print(f\"Cleaned dataset size: {len(X)} pixels.\")\n",
        "\n",
        "# --- 3. SCALING & K-MEANS ---\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"Running MiniBatchKMeans...\")\n",
        "kmeans = MiniBatchKMeans(n_clusters=12, random_state=42, batch_size=2048, n_init=3)\n",
        "clusters = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "X_combined = np.column_stack([X, clusters])\n",
        "\n",
        "# --- 4. RANDOM FOREST ---\n",
        "print(\"Training Random Forest...\")\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=15,\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "rf.fit(X_combined, y)\n",
        "\n",
        "print(\"\\n\" + \"=\"*45)\n",
        "print(\"FINAL PIXEL-LEVEL REPORT\")\n",
        "print(\"=\"*45)\n",
        "y_pred = rf.predict(X_combined)\n",
        "print(classification_report(y, y_pred, target_names=le.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wytuYGj3RdmG",
        "outputId": "da296975-f56a-4eea-ffac-3f8c27f5df08"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sub-sampling classes to a max of 100000...\n",
            "Cleaned dataset size: 786092 pixels.\n",
            "Running MiniBatchKMeans...\n",
            "Training Random Forest...\n",
            "\n",
            "=============================================\n",
            "FINAL PIXEL-LEVEL REPORT\n",
            "=============================================\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "      Grassland       0.95      0.13      0.23    100000\n",
            "          Swamp       0.88      0.12      0.21    100000\n",
            "    Swamp reeds       0.59      0.64      0.61     15882\n",
            "Tree plantation       1.00      0.43      0.60    100000\n",
            "            bog       0.86      0.26      0.40    100000\n",
            "   bog woodland       0.88      0.54      0.67    100000\n",
            "    fen & flush       0.93      0.34      0.50    100000\n",
            "          water       0.13      1.00      0.23     70210\n",
            "         willow       0.86      0.29      0.44    100000\n",
            "\n",
            "       accuracy                           0.37    786092\n",
            "      macro avg       0.79      0.42      0.43    786092\n",
            "   weighted avg       0.83      0.37      0.42    786092\n",
            "\n"
          ]
        }
      ]
    }
  ]
}