{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2im0a34B2H3MZrXT8mU59",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CiaraFarrellSETU/phd/blob/main/Polardstown_cnn_%26HIREsvm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Yo_hupvNRzJu"
      },
      "outputs": [],
      "source": [
        "\n",
        "import rasterio\n",
        "from rasterio.mask import mask\n",
        "from rasterio.enums import Resampling\n",
        "from rasterio.warp import reproject\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from shapely.geometry import mapping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_path = \"/content/pollardstown_ortho.tif\"\n",
        "ndvi_path = \"/content/Pollardstown_Summer_NDVI.tif\"\n",
        "shapefile_path = \"/content/Pollardstown_clappied.shp\""
      ],
      "metadata": {
        "id": "xKA6GR2wSNHS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_src = rasterio.open(rgb_path)\n",
        "ndvi_src = rasterio.open(ndvi_path)"
      ],
      "metadata": {
        "id": "ZuNB1f0GSRd6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "scale_factor = 0.1  # Reduce resolution by 90% (adjust as needed)\n",
        "new_height = int(rgb_src.height * scale_factor)\n",
        "new_width = int(rgb_src.width * scale_factor)\n",
        "\n",
        "print(f\"Downsampling to {new_width} x {new_height} pixels...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKvjCIyJoZHL",
        "outputId": "a0933276-92af-4040-a677-7a9db491a18c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downsampling to 4000 x 4000 pixels...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rgb_resampled = np.empty((3, new_height, new_width), dtype=np.float32)\n",
        "for i in range(1, 4):\n",
        "    reproject(\n",
        "        source=rasterio.band(rgb_src, i),\n",
        "        destination=rgb_resampled[i-1],\n",
        "        src_transform=rgb_src.transform,\n",
        "        src_crs=rgb_src.crs,\n",
        "        dst_transform=rgb_src.transform,\n",
        "        dst_crs=rgb_src.crs,\n",
        "        resampling=Resampling.average,\n",
        "        num_threads=2\n",
        "    )\n"
      ],
      "metadata": {
        "id": "8rZLSErPogar"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ndvi_resampled = np.empty((new_height, new_width), dtype=np.float32)\n",
        "reproject(\n",
        "    source=rasterio.band(ndvi_src, 1),\n",
        "    destination=ndvi_resampled,\n",
        "    src_transform=ndvi_src.transform,\n",
        "    src_crs=ndvi_src.crs,\n",
        "    dst_transform=rgb_src.transform,\n",
        "    dst_crs=rgb_src.crs,\n",
        "    resampling=Resampling.average,\n",
        "    num_threads=2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f541DfNlokc6",
        "outputId": "0855011b-edf6-4340-a011-801b2e313dba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,\n",
              "         -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],\n",
              "        [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,\n",
              "         -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],\n",
              "        [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,\n",
              "         -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],\n",
              "        ...,\n",
              "        [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,\n",
              "         -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],\n",
              "        [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,\n",
              "         -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],\n",
              "        [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,\n",
              "         -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]], dtype=float32),\n",
              " Affine(0.02999680000000226, 0.0, 676477.6457004823,\n",
              "        0.0, -0.029996799999996437, 717008.3241714993))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stacked = np.vstack([rgb_resampled, ndvi_resampled[np.newaxis, ...]])  # shape: (4, H, W"
      ],
      "metadata": {
        "id": "SYEyP-cHomx6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "habitats = gpd.read_file(shapefile_path)"
      ],
      "metadata": {
        "id": "ZYr0R0ZwSbS5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "patch_size = 64\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for idx, row in habitats.iterrows():\n",
        "    geom = [mapping(row['geometry'])]\n",
        "    label = row['Id']  # Adjust to your shapefile attribute name\n",
        "\n",
        "    # Calculate bounding box in downsampled coordinates\n",
        "    # Convert polygon to raster indices\n",
        "    bounds = row['geometry'].bounds\n",
        "    minx, miny, maxx, maxy = bounds\n",
        "\n",
        "    # Convert to pixel indices\n",
        "    col_start = int((minx - rgb_src.bounds.left) / (rgb_src.res[0] / (1/scale_factor)))\n",
        "    col_end = int((maxx - rgb_src.bounds.left) / (rgb_src.res[0] / (1/scale_factor)))\n",
        "    row_start = int((rgb_src.bounds.top - maxy) / (rgb_src.res[1] / (1/scale_factor)))\n",
        "    row_end = int((rgb_src.bounds.top - miny) / (rgb_src.res[1] / (1/scale_factor)))\n",
        "\n",
        "    # Clip from downsampled stack\n",
        "    clipped = stacked[:, row_start:row_end, col_start:col_end]\n",
        "\n",
        "    # Create patches\n",
        "    h, w = clipped.shape[1], clipped.shape[2]\n",
        "    for i in range(0, h - patch_size, patch_size):\n",
        "        for j in range(0, w - patch_size, patch_size):\n",
        "            patch = clipped[:, i:i+patch_size, j:j+patch_size]\n",
        "            if patch.shape[1] == patch_size and patch.shape[2] == patch_size:\n",
        "                X.append(patch.transpose(1, 2, 0))  # (H, W, Channels)\n",
        "                y.append(label)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n"
      ],
      "metadata": {
        "id": "CI2xowc2ozMS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "y_onehot = to_categorical(y_encoded)\n"
      ],
      "metadata": {
        "id": "k0_JLXg7Sgul"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "7mKvlkfQSjDu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n"
      ],
      "metadata": {
        "id": "KfZ7MVdOSm4d"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_classes = y_onehot.shape[1]\n",
        "\n",
        "\n",
        "from tensorflow.keras import Input, layers, models\n",
        "\n",
        "model = models.Sequential([\n",
        "    Input(shape=(patch_size, patch_size, 4)),  # Explicit input layer\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "_fxDKRlISnf9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCnhemSQSrEC",
        "outputId": "187ce944-6cea-4ea3-9df7-e4657215b233"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 2/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 3/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 185ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 4/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 163ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 5/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 184ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 6/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 190ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 7/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 8/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 164ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 9/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 190ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 10/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 11/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 166ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 12/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 13/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 171ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 14/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 15/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 188ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 16/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 163ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 17/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 170ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 18/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 19/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 20/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e26ebbb6db0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {acc:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO_NHqphSrcz",
        "outputId": "e80fa2da-5a94-4ad3-91ee-75ce430f3546"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Test Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred_onehot = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_onehot, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLByU16lq3QE",
        "outputId": "dcfc3a0e-d637-404a-f96e-baab55a50784"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step\n",
            "Confusion Matrix:\n",
            "[[496]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F9Kl-Ng6rbXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "# Check unique classes and their counts\n",
        "classes, counts = np.unique(y, return_counts=True)\n",
        "\n",
        "print(\"Class Distribution:\")\n",
        "for cls, cnt in zip(classes, counts):\n",
        "    print(f\"{cls}: {cnt} samples\")\n",
        "\n",
        "# If you used LabelEncoder, you can map back to class names:\n",
        "print(\"\\nMapped Class Names:\")\n",
        "for cls, cnt in zip(classes, counts):\n",
        "    print(f\"{encoder.classes_[cls]}: {cnt} samples\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "WeM7c0W-rbZ7",
        "outputId": "7a682f2e-51e8-45dc-ebe4-ca4964ca17c6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution:\n",
            "15: 2480 samples\n",
            "\n",
            "Mapped Class Names:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 15 is out of bounds for axis 0 with size 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3143155526.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nMapped Class Names:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{encoder.classes_[cls]}: {cnt} samples\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: index 15 is out of bounds for axis 0 with size 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import geopandas as gpd\n",
        "\n",
        "# Load shapefile\n",
        "shapefile_path = \"/content/Pollardstown_clappied.shp\"\n",
        "habitats = gpd.read_file(shapefile_path)\n",
        "\n",
        "# Check available columns\n",
        "print(\"Columns in shapefile:\", habitats.columns)\n",
        "\n",
        "# Verify unique habitat types using 'Id' column\n",
        "if 'Id' in habitats.columns:\n",
        "    unique_types = habitats['Id'].unique()\n",
        "    print(\"\\nUnique Habitat Types:\")\n",
        "    for t in unique_types:\n",
        "        print(\"-\", t)\n",
        "    print(f\"\\nTotal unique habitat types: {len(unique_types)}\")\n",
        "else:\n",
        "    print(\"Column 'Id' not found. Please check the correct attribute name.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q16TU-TAr0mj",
        "outputId": "29df2d08-50e0-4639-bb83-add35def8db0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in shapefile: Index(['Id', 'NFS_Code', 'NFS_Name', 'County', 'Co_Code', 'Area_sqm',\n",
            "       'Area_ha', 'Poly_Num', '7140', '7210', '7230', '6410', '6430', '91E0',\n",
            "       'OtherAnnex', 'PF1', 'PF2', 'PF3', 'FS1', 'FS2', 'GS1', 'GS2', 'GS3',\n",
            "       'GS4', 'GM1', 'GA1', 'WS1', 'WN2', 'WN4', 'WN6', 'WN7', 'WL1', 'WL2',\n",
            "       'PB1', 'PB2', 'PB3', 'PB4', 'PB5', 'FW4', 'HH3', 'OtherFossi',\n",
            "       'SumAnnex', 'SumFossit', 'DataQual', 'Anx_Mapped', 'Non_Anx_PF',\n",
            "       'PRIMARY_FO', 'Anx_perc', 'Anx_perc_l', 'geometry'],\n",
            "      dtype='object')\n",
            "\n",
            "Unique Habitat Types:\n",
            "- 19\n",
            "- 15\n",
            "- 10\n",
            "- 9\n",
            "- 12\n",
            "- 2\n",
            "- 18\n",
            "- 13\n",
            "- 20\n",
            "- 16\n",
            "- 14\n",
            "- 17\n",
            "- 11\n",
            "\n",
            "Total unique habitat types: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xSYGRTPpsOYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HIRE svm"
      ],
      "metadata": {
        "id": "_B9frrb0xGkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "import rasterio\n",
        "from rasterio.warp import reproject, Resampling\n",
        "from rasterio.features import rasterize\n",
        "from shapely.geometry import box\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n"
      ],
      "metadata": {
        "id": "yDQuwCTszv3g"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rgb_path = \"/content/pollardstown_ortho.tif\"\n",
        "ndvi_path = \"/content/Pollardstown_Summer_NDVI.tif\"\n",
        "habitat_shp = \"/content/Pollardstown_clappied.shp\"\n"
      ],
      "metadata": {
        "id": "UpP3ly0l0QSO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tile_size = 1024  # Adjust based on memory\n",
        "max_samples_per_tile = 1000\n",
        "three_class_map = {\n",
        "    2: 1, 9: 1, 10: 1, 11: 1,           # Fen\n",
        "    12: 2, 13: 2, 14: 2,                # Grassland\n",
        "    15: 3, 16: 3, 17: 3, 18: 3, 19: 3, 20: 3 # Woody/Mosaic\n",
        "}\n"
      ],
      "metadata": {
        "id": "xs7H4ijd0pse"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf = gpd.read_file(habitat_shp)"
      ],
      "metadata": {
        "id": "4uoVkjfp0vT2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_samples = []\n",
        "y_samples = []\n",
        "\n",
        "with rasterio.open(rgb_path) as src_rgb, rasterio.open(ndvi_path) as src_ndvi:\n",
        "    for i in range(0, src_rgb.height, tile_size):\n",
        "        for j in range(0, src_rgb.width, tile_size):\n",
        "            window = rasterio.windows.Window(j, i, tile_size, tile_size)\n",
        "            tile_bounds = rasterio.windows.bounds(window, transform=src_rgb.transform)\n",
        "\n",
        "            # Clip polygons to tile extent\n",
        "            tile_geom = box(*tile_bounds)\n",
        "            gdf_tile = gdf[gdf.intersects(tile_geom)]\n",
        "\n",
        "            if gdf_tile.empty:\n",
        "                continue  # No training data in this tile\n",
        "\n",
        "            # Read RGB tile\n",
        "            rgb_tile = src_rgb.read([1, 2, 3], window=window)\n",
        "            rgb_tile = np.transpose(rgb_tile, (1, 2, 0))\n",
        "\n",
        "            # Resample NDVI tile\n",
        "            ndvi_tile = np.empty((tile_size, tile_size), dtype=np.float32)\n",
        "            reproject(\n",
        "                source=rasterio.band(src_ndvi, 1),\n",
        "                destination=ndvi_tile,\n",
        "                src_transform=src_ndvi.transform,\n",
        "                src_crs=src_ndvi.crs,\n",
        "                dst_transform=src_rgb.window_transform(window),\n",
        "                dst_crs=src_rgb.crs,\n",
        "                resampling=Resampling.bilinear\n",
        "            )\n",
        "            ndvi_tile = ndvi_tile[..., np.newaxis]\n",
        "\n",
        "            # Stack RGB + NDVI\n",
        "            img_tile = np.concatenate([rgb_tile, ndvi_tile], axis=-1)\n",
        "\n",
        "            # Rasterise polygons for this tile\n",
        "            shapes = [(geom, value) for geom, value in zip(gdf_tile.geometry, gdf_tile['Id'])]\n",
        "            mask_tile = rasterize(shapes, out_shape=(tile_size, tile_size),\n",
        "                                  transform=src_rgb.window_transform(window), fill=0)\n",
        "\n",
        "            # Apply mapping safely\n",
        "            mask_tile = np.vectorize(lambda x: three_class_map.get(x, 0))(mask_tile)\n",
        "\n",
        "            # Extract samples where mask > 0\n",
        "            rows, cols = np.where(mask_tile > 0)\n",
        "            if len(rows) > 0:\n",
        "                # Random sampling to avoid memory overload\n",
        "                idx = np.random.choice(len(rows), size=min(max_samples_per_tile, len(rows)), replace=False)\n",
        "                X_samples.append(img_tile[rows[idx], cols[idx]])\n",
        "                y_samples.append(mask_tile[rows[idx], cols[idx]])\n",
        "\n",
        "# Combine sampled data\n",
        "X_samples = np.vstack(X_samples)\n",
        "y_samples = np.hstack(y_samples)\n",
        "print(\"Training samples:\", X_samples.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIGh0zQ43hxQ",
        "outputId": "bba2a8ce-a600-4062-d755-46d3b0df9f41"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: (340644, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_samples, y_samples, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "kGrnNc0F4q8w"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "clf = SGDClassifier(loss='hinge', max_iter=1000, tol=1e-3, class_weight='balanced')\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "k7nxaq-s8fI1",
        "outputId": "e947b25c-92f2-47d8-9a94-a464a6d45ab7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Floating-point under-/overflow occurred at epoch #1. Scaling input data with StandardScaler or MinMaxScaler might help.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-179752891.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hinge'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_more_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         return self._fit(\n\u001b[0m\u001b[1;32m    933\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         self._partial_fit(\n\u001b[0m\u001b[1;32m    720\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# delegate to concrete training procedure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m             self._fit_multiclass(\n\u001b[0m\u001b[1;32m    644\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit_multiclass\u001b[0;34m(self, X, y, alpha, C, learning_rate, sample_weight, max_iter)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0mseeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_INT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m         result = Parallel(\n\u001b[0m\u001b[1;32m    799\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sharedmem\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1984\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1986\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1912\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1914\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1915\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit_binary\u001b[0;34m(est, i, X, y, alpha, C, learning_rate, max_iter, pos_weight, neg_weight, sample_weight, validation_mask, random_state)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0m_plain_sgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_plain_sgd_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m     coef, intercept, average_coef, average_intercept, n_iter_ = _plain_sgd(\n\u001b[0m\u001b[1;32m    457\u001b[0m         \u001b[0mcoef\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0mintercept\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msklearn/linear_model/_sgd_fast.pyx\u001b[0m in \u001b[0;36msklearn.linear_model._sgd_fast._plain_sgd32\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Floating-point under-/overflow occurred at epoch #1. Scaling input data with StandardScaler or MinMaxScaler might help."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_repor\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "gXqsZdQI8Vd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mJjzn7eT_XAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bNWIh93e_XDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import rasterio\n",
        "from rasterio.warp import reproject, Resampling\n",
        "from rasterio.features import rasterize\n",
        "from shapely.geometry import box\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n"
      ],
      "metadata": {
        "id": "jR4aFF5UAorF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rgb_path = \"/content/pollardstown_ortho.tif\"\n",
        "ndvi_path = \"/content/Pollardstown_Summer_NDVI.tif\"\n",
        "habitat_shp = \"/content/Pollardstown_clappied.shp\"\n",
        "\n",
        "tile_size = 1024  # Adjust based on memory\n",
        "max_samples_per_tile = 1000  # Limit samples per tile\n",
        "batch_size = 50000  # For incremental training\n",
        "three_class_map = {\n",
        "    2: 1, 9: 1, 10: 1, 11: 1,           # Fen\n",
        "    12: 2, 13: 2, 14: 2,                # Grassland\n",
        "    15: 3, 16: 3, 17: 3, 18: 3, 19: 3, 20: 3 # Woody/Mosaic\n",
        "}\n"
      ],
      "metadata": {
        "id": "avxN7DIj_XGC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf = gpd.read_file(habitat_shp)"
      ],
      "metadata": {
        "id": "qNC5L4T-_ZsZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X_samples = []\n",
        "y_samples = []\n",
        "\n",
        "with rasterio.open(rgb_path) as src_rgb, rasterio.open(ndvi_path) as src_ndvi:\n",
        "    for i in range(0, src_rgb.height, tile_size):\n",
        "        for j in range(0, src_rgb.width, tile_size):\n",
        "            window = rasterio.windows.Window(j, i, tile_size, tile_size)\n",
        "            tile_bounds = rasterio.windows.bounds(window, transform=src_rgb.transform)\n",
        "\n",
        "            # Clip polygons to tile extent\n",
        "            tile_geom = box(*tile_bounds)\n",
        "            gdf_tile = gdf[gdf.intersects(tile_geom)]\n",
        "\n",
        "            if gdf_tile.empty:\n",
        "                continue\n",
        "\n",
        "            # Read RGB tile\n",
        "            rgb_tile = src_rgb.read([1, 2, 3], window=window)\n",
        "            rgb_tile = np.transpose(rgb_tile, (1, 2, 0))\n",
        "\n",
        "            # Resample NDVI tile\n",
        "            ndvi_tile = np.empty((tile_size, tile_size), dtype=np.float32)\n",
        "            reproject(\n",
        "                source=rasterio.band(src_ndvi, 1),\n",
        "                destination=ndvi_tile,\n",
        "                src_transform=src_ndvi.transform,\n",
        "                src_crs=src_ndvi.crs,\n",
        "                dst_transform=src_rgb.window_transform(window),\n",
        "                dst_crs=src_rgb.crs,\n",
        "                resampling=Resampling.bilinear\n",
        "            )\n",
        "            ndvi_tile = ndvi_tile[..., np.newaxis]\n",
        "\n",
        "            # Stack RGB + NDVI\n",
        "            img_tile = np.concatenate([rgb_tile, ndvi_tile], axis=-1)\n",
        "\n",
        "            # Rasterise polygons for this tile\n",
        "            shapes = [(geom, value) for geom, value in zip(gdf_tile.geometry, gdf_tile['Id'])]\n",
        "            mask_tile = rasterize(shapes, out_shape=(tile_size, tile_size),\n",
        "                                  transform=src_rgb.window_transform(window), fill=0)\n",
        "\n",
        "            # Apply mapping safely\n",
        "            mask_tile = np.vectorize(lambda x: three_class_map.get(x, 0))(mask_tile)\n",
        "\n",
        "            # Extract samples where mask > 0\n",
        "            rows, cols = np.where(mask_tile > 0)\n",
        "            if len(rows) > 0:\n",
        "                idx = np.random.choice(len(rows), size=min(max_samples_per_tile, len(rows)), replace=False)\n",
        "                X_samples.append(img_tile[rows[idx], cols[idx]])\n",
        "                y_samples.append(mask_tile[rows[idx], cols[idx]])\n",
        "\n",
        "# Combine sampled data\n",
        "X_samples = np.vstack(X_samples)\n",
        "y_samples = np.hstack(y_samples)\n",
        "print(\"Collected samples:\", X_samples.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zLOcfhq_bwx",
        "outputId": "c982bb11-645a-4ca5-d21e-de2ac2f128ad"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collected samples: (340644, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "classes = np.unique(y_samples)\n",
        "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_samples)\n",
        "class_weight_dict = dict(zip(classes, weights))\n",
        "print(\"Class weights:\", class_weight_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3OBg_FiA0ie",
        "outputId": "c3e83026-1970-44ce-edc3-71bcdca9886e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {np.int64(1): np.float64(0.4592882625613811), np.int64(2): np.float64(1.9837523366935133), np.int64(3): np.float64(3.138505763011692)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "clf = SGDClassifier(loss='hinge', max_iter=1000, tol=None, class_weight=class_weight_dict)\n",
        "\n",
        "# Incremental training in batches\n",
        "for start in range(0, len(X_samples), batch_size):\n",
        "    end = start + batch_size\n",
        "    X_batch = scaler.fit_transform(X_samples[start:end])\n",
        "    y_batch = y_samples[start:end]\n",
        "    clf.partial_fit(X_batch, y_batch, classes=classes)\n",
        "\n",
        "# Save model and scaler\n",
        "joblib.dump(clf, \"sgd_habitat_model.pkl\")\n",
        "joblib.dump(scaler, \"scaler.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kVuQd2NA3Ws",
        "outputId": "6aed61f4-f5ed-436a-a4a1-516241c3410d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scaler.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = clf.predict(scaler.transform(X_test))\n",
        "print(classification_report(y_test, y_pred_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HD25AzuBA5A9",
        "outputId": "542161d5-6917-4ea8-a9f9-ef11a95371b4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.73      1.00      0.84     49430\n",
            "           2       0.00      0.00      0.00     11404\n",
            "           3       0.00      0.00      0.00      7295\n",
            "\n",
            "    accuracy                           0.73     68129\n",
            "   macro avg       0.24      0.33      0.28     68129\n",
            "weighted avg       0.53      0.73      0.61     68129\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}